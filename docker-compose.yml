services:
  llcar:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: llcar-pipeline
    environment:
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      # Mount local directories for input/output
      - ./input:/app/input:ro
      - ./output:/app/output
      - ./models:/app/models
      # Mount config if customized
      - ./config.yaml:/app/config.yaml:ro
    # GPU support (uncomment if using NVIDIA GPU)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    command: --help

  # Example: Process a specific video
  # llcar-process:
  #   extends: llcar
  #   command: --video /app/input/video.mp4 --language en --formats json txt csv
